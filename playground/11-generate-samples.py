
# Instantiate the generator
gen = Generator()

# Load the trained generator weights
gen.load_state_dict(torch.load('gen_weights.pth'))

# Generate new samples
n_samples = 10
noise = torch.randn(n_samples, 3) # Generate random noise
class_labels = torch.randint(0, n_classes, (n_samples, 3)) # Generate random class labels
generated_data = gen(noise, class_labels)

# The generated_data variable will now contain the generated samples.

"""
Here, n_samples is the number of samples you want to generate. In this example, noise is generated by sampling from a standard normal distribution with shape (n_samples, 3), and class_labels is generated by sampling from a uniform distribution with shape (n_samples, 3) and with n_classes possible values. Then, the generator is passed both the noise and class_labels.
The gen.load_state_dict(torch.load('gen_weights.pth')) loads the previously trained weights of generator.

You can also use this approach to generate samples for specific classes by specifying the desired class labels instead of generating random class labels.

You can also use this generated data for any other use case like generating new images, videos, audio etc.
"""

## save models
# Save the generator
torch.save(gen.state_dict(), 'gen_weights.pth')

# Save the discriminator
torch.save(disc.state_dict(), 'disc_weights.pth')

"""
This will save the generator and discriminator parameters to the specified file path. The gen_weights.pth and disc_weights.pth can be used later to load the model and generate new samples or use it in other use cases.

You can also use torch.save(model, PATH) to save the whole model with its architecture and optimizer state. It will save the whole state of the model in a single file in the disk.

It's also good practice to save the model after every certain number of epochs during the training process, so that you can always return to a previously saved model in case something goes wrong during the training process or if you want to resume training from that point.
"""
